{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = pd.read_json(\"model_judgment/claude-3-5-sonnet-20240620/claude-2.1.jsonl\", lines=True)\n",
    "example.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example[\"games\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example[\"games\"][0][0][\"user_prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example[\"games\"][0][0][\"user_prompt\"][15:1180].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_preprocess(file_path):\n",
    "    final_data = pd.DataFrame(columns=[\"id\", \"prompt\", \"response_a\", \"response_b\", \"winner_model_a\", \"winner_model_b\", \"winner_model_tie\", \"answer_model\", \"judge_model\"])\n",
    "    data = pd.read_json(file_path, lines=True)\n",
    "    for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        for judge in row[\"games\"]:\n",
    "            try:\n",
    "                text = judge[\"user_prompt\"]\n",
    "                prompt = text[15: text.find('<|The Start of Assistant A\\'s Answer|>')].strip()\n",
    "                response_a = text[text.find('<|The Start of Assistant A\\'s Answer|>') + len('<|The Start of Assistant A\\'s Answer|>'): text.find('<|The End of Assistant A\\'s Answer|>')].strip()\n",
    "                response_b = text[text.find('<|The Start of Assistant B\\'s Answer|>') + len('<|The Start of Assistant B\\'s Answer|>'): text.find('<|The End of Assistant B\\'s Answer|>')].strip()\n",
    "                if judge[\"score\"] == \"A=B\":\n",
    "                    winner_model_a = 0\n",
    "                    winner_model_b = 0\n",
    "                    winner_model_tie = 1\n",
    "                elif judge[\"score\"] == \"A>B\" or judge[\"score\"] == \"B<A\":\n",
    "                    winner_model_a = 1\n",
    "                    winner_model_b = 0\n",
    "                    winner_model_tie = 0\n",
    "                elif judge[\"score\"] == \"A<B\" or judge[\"score\"] == \"B>A\":\n",
    "                    winner_model_a = 0\n",
    "                    winner_model_b = 1\n",
    "                    winner_model_tie = 0\n",
    "                new_row = {\n",
    "                    \"id\": row[\"question_id\"],\n",
    "                    \"prompt\": [prompt],\n",
    "                    \"response_a\": [response_a],\n",
    "                    \"response_b\": [response_b],\n",
    "                    \"winner_model_a\": winner_model_a,\n",
    "                    \"winner_model_b\": winner_model_b,\n",
    "                    \"winner_model_tie\": winner_model_tie,\n",
    "                    \"answer_model\": row[\"model\"],\n",
    "                    \"judge_model\": row[\"judge\"]\n",
    "                }\n",
    "                new_row_df = pd.DataFrame([new_row], columns=final_data.columns)\n",
    "                final_data = pd.concat([final_data, new_row_df], ignore_index=True)\n",
    "            except:\n",
    "                print(\"Error\")\n",
    "                continue\n",
    "    print(type(final_data[\"prompt\"][0]))\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_preprocess(\"model_judgment/claude-3-5-sonnet-20240620/claude-2.1.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = [\"model_judgment/claude-3-5-sonnet-20240620\", \"model_judgment/claude-3-opus-20240229\", \"model_judgment/gemini-1.5-pro-api-0514\", \"model_judgment/gpt-4-1106-preview\", \"model_judgment/llama-3-70b-instruct\"]\n",
    "\n",
    "possible_leak_data = pd.DataFrame(columns=[\"id\", \"prompt\", \"response_a\", \"response_b\", \"winner_model_a\", \"winner_model_b\", \"winner_model_tie\", \"answer_model\", \"judge_model\"])\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path) and file_name.endswith(\".jsonl\"):\n",
    "            final_data = file_preprocess(file_path)\n",
    "            possible_leak_data = pd.concat([possible_leak_data, final_data], ignore_index=True)\n",
    "\n",
    "print(possible_leak_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
