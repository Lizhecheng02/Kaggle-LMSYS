{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fd5a5-9ea1-4009-a4f5-14f8ecd6b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn transformers peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06762a62-6035-4580-a70a-8578f5a58fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import log_loss\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import PeftModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def seed_everything(seed=None):\n",
    "    \"\"\"\n",
    "    固定seed\n",
    "    :param seed: int, 随机种子\n",
    "    \"\"\"\n",
    "    max_seed_value = np.iinfo(np.uint32).max\n",
    "    min_seed_value = np.iinfo(np.uint32).min\n",
    "\n",
    "    if (seed is None) or not (min_seed_value <= seed <= max_seed_value):\n",
    "        seed = random.randint(np.iinfo(np.uint32).min, np.iinfo(np.uint32).max)\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    return seed\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bff1ac-64e9-4bcc-8537-c25a29776cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionDataSet(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_source_length, max_target_length):\n",
    "        super(InstructionDataSet, self).__init__()\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        now_data = self.data.loc[index]\n",
    "        idx = now_data[\"id\"]\n",
    "        templete_part1 = \"<start_of_turn>user\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\\n\"\n",
    "        templete_part1_input_ids = self.tokenizer(text=templete_part1, add_special_tokens=True, padding=False)[\"input_ids\"]\n",
    "\n",
    "        templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<end_of_turn>\\n\"\n",
    "        templete_part2_input_ids = self.tokenizer(text=templete_part2, add_special_tokens=True, padding=False)[\"input_ids\"][1:]\n",
    "  \n",
    "        templete_part3 = \"<start_of_turn>model\\n\"\n",
    "        templete_part3_input_ids = self.tokenizer(text=templete_part3, add_special_tokens=True, padding=False)[\"input_ids\"][1:]\n",
    "        prompt_response = now_data[\"prompt_response\"]\n",
    "\n",
    "        prompt_response_ids = self.tokenizer(\n",
    "            text=prompt_response, \n",
    "            add_special_tokens=True, \n",
    "            truncation=True,\n",
    "            max_length=self.max_source_length, \n",
    "            padding=False\n",
    "        )[\"input_ids\"][1:]\n",
    "\n",
    "        input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids\n",
    "        input_text = self.tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": input_text,\n",
    "            \"id\": idx\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506790b9-c1ff-44f8-84a2-d2a186593f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch = {k: [item[k] for item in batch] for k in (\"input_ids\", \"id\")}\n",
    "    batch_input = tokenizer(\n",
    "        batch[\"input_ids\"],\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LENGTH + 50\n",
    "    )\n",
    "    return batch_input, batch[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0208959-dfd7-4218-b958-a367f9521742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_split_data\n",
    "data_path = \"../data/train.csv\"\n",
    "prompt_type = 2\n",
    "MAX_INPUT = 2300\n",
    "if_train = True\n",
    "df_train, df_valid = load_split_data(data_path, prompt_type, MAX_INPUT, if_train, True)\n",
    "test = df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1d9e5-14ed-4ba4-b701-dc878f211a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_dataloader):\n",
    "    test_predictions = []\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        batch_input, idx = batch\n",
    "        for k in batch_input.keys():\n",
    "            batch_input[k] = batch_input[k].to(device)\n",
    "        with torch.no_grad():\n",
    "            response = model.generate(**batch_input, max_new_tokens=1, return_dict_in_generate=True, output_scores=True)\n",
    "            score = response.scores[0]\n",
    "            A_prob, B_prob, C_prob = score[:, A_TOKEN_IDS], score[:, B_TOKEN_IDS], score[:, C_TOKEN_IDS]\n",
    "            logits = torch.Tensor([[A_prob, B_prob, C_prob]])\n",
    "            logits = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "            node_result = [[idx[i], logits[i]] for i in range(batch_size)]\n",
    "        test_predictions.append(node_result)\n",
    "    return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5600585-ab23-4b1c-a723-7c6ab546e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cc96ee-74c1-4f9a-a50d-9a3598330116",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"google/gemma-2-9b-it\"\n",
    "model_path = \"./lmsys/checkpoint-2300\"\n",
    "MAX_LENGTH = 2300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af0d60-712e-4efa-b0cd-3731f3198ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, truncation_side=\"left\")\n",
    "config = AutoConfig.from_pretrained(base_model, trust_remote_code=True, token=\"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\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "base_model_0 = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    config=config,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    token=\"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\"\n",
    ")\n",
    "\n",
    "new_model = model_path\n",
    "model0 = PeftModel.from_pretrained(base_model_0, new_model).to(device)\n",
    "model0.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a3f5e-455d-4318-ad64-02280a99aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_TOKEN_IDS = tokenizer(\"A\", add_special_tokens=True, truncation=True, max_length=1024)[\"input_ids\"][1:]\n",
    "B_TOKEN_IDS = tokenizer(\"B\", add_special_tokens=True, truncation=True, max_length=1024)[\"input_ids\"][1:]\n",
    "C_TOKEN_IDS = tokenizer(\"C\", add_special_tokens=True, truncation=True, max_length=1024)[\"input_ids\"][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ba1af6-413e-4fdb-9357-9d7094743e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_TOKEN_IDS, B_TOKEN_IDS, C_TOKEN_IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6cf97a-1ad2-4cdb-92c1-17690144d40d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "tokenized_dataset = InstructionDataSet(test, tokenizer, MAX_LENGTH, 1)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(tokenized_dataset, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e194ff9-be6d-4472-a28b-b30b91a334a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_pred = inference(model=model0, test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87381f51-1930-4d19-8c61-c0196e9196a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "for item in sub_pred:\n",
    "    item = item[0]\n",
    "    id = item[0].item()  \n",
    "    array_values = item[1].tolist()  \n",
    "    processed_data.append([id] + array_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad7e3bf-a0b1-4249-ba3c-68b6e632dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = [\"id\", \"winner_model_a\", \"winner_model_b\", \"winner_tie\"]\n",
    "df = pd.DataFrame(processed_data, columns=new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b08e7ca-463a-4554-b57d-0b0385d21238",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(\"id\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef037aac-5011-48eb-ad82-e1f35d2ee2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba02d2-3deb-46af-90ff-4b95e46fbcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "str2num = {\"A\": 0, \"B\": 1, \"C\": 2}\n",
    "test[\"label_number\"] = test.label.map(str2num)\n",
    "prediction = np.array(df[new_columns[1:]])\n",
    "test = test.drop_duplicates(subset=[\"id\"]).reset_index(drop=True)\n",
    "log_loss(test.label_number, prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
