{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 18.361615,
     "end_time": "2024-06-29T18:08:32.870023",
     "exception": false,
     "start_time": "2024-06-29T18:08:14.508408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import ctypes\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import log_loss\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def seed_everything(seed=None):\n",
    "    \"\"\"\n",
    "    固定seed\n",
    "    :param seed: int, 随机种子\n",
    "    \"\"\"\n",
    "    max_seed_value = np.iinfo(np.uint32).max\n",
    "    min_seed_value = np.iinfo(np.uint32).min\n",
    "\n",
    "    if (seed is None) or not (min_seed_value <= seed <= max_seed_value):\n",
    "        seed = random.randint(np.iinfo(np.uint32).min, np.iinfo(np.uint32).max)\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    return seed\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.018623,
     "end_time": "2024-06-29T18:08:32.899371",
     "exception": false,
     "start_time": "2024-06-29T18:08:32.880748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (not torch.cuda.is_available()):\n",
    "    print(\"Sorry - GPU Required!\")\n",
    "\n",
    "MAX_LENGTH = 2300\n",
    "INFERENCE_MAX_LENGTH = [2300]\n",
    "TRAINING_MODEL_PATH = [\"../data/checkpoint-1800_8685\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.024469,
     "end_time": "2024-06-29T18:08:32.934548",
     "exception": false,
     "start_time": "2024-06-29T18:08:32.910079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InstructionDataSet(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_source_length, max_target_length):\n",
    "        super(InstructionDataSet, self).__init__()\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        now_data = self.data.loc[index]\n",
    "        idx = now_data[\"id\"]\n",
    "        templete_part1 = \"<start_of_turn>user\\nHere are two question-answering dialogues. Compare two model performance on answering question, determine which is better.\\n\\n\"\n",
    "        templete_part1_input_ids = self.tokenizer(text=templete_part1, add_special_tokens=True, padding=False)[\"input_ids\"]\n",
    "\n",
    "        templete_part2 = \"\\n###options\\nA. Model A\\nB. Model B\\nC. Tie\\n<end_of_turn>\\n\"\n",
    "        templete_part2_input_ids = self.tokenizer(text=templete_part2, add_special_tokens=True, padding=False)[\"input_ids\"][1:]\n",
    "\n",
    "        templete_part3 = \"<start_of_turn>model\\n\"\n",
    "        templete_part3_input_ids = self.tokenizer(text=templete_part3, add_special_tokens=True, padding=False)[\"input_ids\"][1:]\n",
    "\n",
    "        prompt_response = now_data[\"prompt_response\"]\n",
    "        prompt_response_ids = self.tokenizer(\n",
    "            text=prompt_response, \n",
    "            add_special_tokens=True, \n",
    "            truncation=True,\n",
    "            max_length=self.max_source_length, \n",
    "            padding=False\n",
    "        )[\"input_ids\"][1:]\n",
    "\n",
    "        input_ids = templete_part1_input_ids + prompt_response_ids + templete_part2_input_ids + templete_part3_input_ids\n",
    "        input_text = self.tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": input_text,\n",
    "            \"id\": idx\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.035532,
     "end_time": "2024-06-29T18:08:32.981587",
     "exception": false,
     "start_time": "2024-06-29T18:08:32.946055",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process(input_str):\n",
    "    return json.loads(input_str)\n",
    "\n",
    "\n",
    "def get_label(row):\n",
    "    label = [idx for idx, option in enumerate([\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]) if row[option] == 1]\n",
    "    if label[-1] == 0:\n",
    "        return \"A\"\n",
    "    elif label[-1] == 1:\n",
    "        return \"B\"\n",
    "    else:\n",
    "        return \"C\"\n",
    "    return label[-1]\n",
    "\n",
    "\n",
    "def load_json(data):\n",
    "    data.loc[:, \"prompt\"] = data[\"prompt\"].apply(process)\n",
    "    data.loc[:, \"response_a\"] = data[\"response_a\"].apply(process)\n",
    "    data.loc[:, \"response_b\"] = data[\"response_b\"].apply(process)\n",
    "    return data\n",
    "\n",
    "\n",
    "def prompt_1(data):\n",
    "    \"\"\"\n",
    "    #Model A\n",
    "    Prompt1: xxx\n",
    "    Response: xxx\n",
    "\n",
    "    Prompt2: xxx\n",
    "    Response: xxx\n",
    "\n",
    "    #Model B\n",
    "    Prompt1: xxx\n",
    "    Response: xxx\n",
    "\n",
    "    Prompt2: xxx\n",
    "    Response: xxx\n",
    "    \"\"\"\n",
    "    data[\"prompt_response_A\"] = \"Prompt: \" + data[\"prompt\"] + \"\\n\" + \"Response: \" + data[\"response_a\"]\n",
    "    data[\"prompt_response_B\"] = \"Prompt: \" + data[\"prompt\"] + \"\\n\" + \"Response: \" + data[\"response_b\"]\n",
    "    data = data.groupby(\"id\").agg({\"prompt_response_A\": \"\\n\\n\".join, \"prompt_response_B\": \"\\n\\n\".join, \"label\": lambda x: list(x)[0]}).reset_index()\n",
    "    data[\"prompt_response\"] = \"#Model A\\n\" + data[\"prompt_response_A\"] + \"\\n\\n#Model B\\n\" + data[\"prompt_response_B\"]\n",
    "    return data\n",
    "\n",
    "\n",
    "def prompt_2(data, max_length, if_train):\n",
    "    \"\"\"\n",
    "    超过max length新开一行，label不变\n",
    "    #Prompt1\n",
    "    xxxx\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "\n",
    "    #Prompt2\n",
    "    #Response\n",
    "    ##Model A\n",
    "    xxxx\n",
    "    ##Model B\n",
    "    xxxx\n",
    "    \"\"\"\n",
    "\n",
    "    data[\"prompt_response\"] = \"#Prompt\\n\" + data[\"prompt\"] + \"\\n\\n\" + \"#Response\\n\" + \"##Model A\\n\" + data[\"response_a\"] + \"\\n\\n\" + \"##Model B\\n\" + data[\"response_b\"]\n",
    "\n",
    "    prompt_response = []\n",
    "    ids = []\n",
    "    labels = []\n",
    "    text_length = 0\n",
    "    for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        text = row[\"prompt_response\"]\n",
    "        if if_train:\n",
    "            label = row[\"label\"]\n",
    "        id = row[\"id\"]\n",
    "        if id not in ids:\n",
    "            prompt_response.append(text)\n",
    "            text_length = len(text.split(\" \"))\n",
    "            ids.append(id)\n",
    "            if if_train:\n",
    "                labels.append(label)\n",
    "        else:\n",
    "            text_length += len(text.split(\" \"))\n",
    "            if text_length <= max_length:\n",
    "                text = prompt_response[-1] + \"\\n\\n\" + text\n",
    "                prompt_response[-1] = text\n",
    "            else:\n",
    "                prompt_response.append(text)\n",
    "                text_length = len(text.split(\" \"))\n",
    "                ids.append(id)\n",
    "                if if_train:\n",
    "                    labels.append(label)\n",
    "    if if_train:\n",
    "        data = pd.DataFrame({\"id\": ids, \"prompt_response\": prompt_response, \"label\": labels})\n",
    "    else:\n",
    "        data = pd.DataFrame({\"id\": ids, \"prompt_response\": prompt_response})\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_split_data(data_path, prompt_type, max_length, if_train, split):\n",
    "    \"\"\"\n",
    "    prompt_type: [1, 2, 3]\n",
    "    if_train: True or False\n",
    "    \"\"\"\n",
    "    if \"csv\" in data_path:\n",
    "        data = pd.read_csv(data_path)\n",
    "        data = load_json(data)\n",
    "    elif \"json\" in data_path:\n",
    "        data = pd.read_json(data_path)\n",
    "\n",
    "    data = data.explode([\"prompt\", \"response_a\", \"response_b\"]).reset_index(drop=True)\n",
    "\n",
    "    if if_train:\n",
    "        data[\"label\"] = data.apply(lambda x: get_label(x), axis=1)\n",
    "\n",
    "    data = data.fillna(\"None\")\n",
    "    data[\"response_a\"] = data[\"response_a\"].apply(lambda x: \"None\" if len(x) == 0 else x)\n",
    "    data[\"response_b\"] = data[\"response_b\"].apply(lambda x: \"None\" if len(x) == 0 else x)\n",
    "\n",
    "    if prompt_type == 1:\n",
    "        data = prompt_1(data)\n",
    "    elif prompt_type == 2:\n",
    "        data = prompt_2(data, max_length * 0.75, if_train)\n",
    "    if split:\n",
    "        idx = data.id.unique()\n",
    "        valid_idx = [idx[i] for i in range(len(idx)) if i % 20 == 0]\n",
    "        valid = data.loc[data.id.isin(valid_idx),].reset_index(drop=True)\n",
    "        train = data.loc[~data.id.isin(valid_idx),].reset_index(drop=True)\n",
    "        return train, valid\n",
    "    \n",
    "    return data, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.054422,
     "end_time": "2024-06-29T18:08:33.047673",
     "exception": false,
     "start_time": "2024-06-29T18:08:32.993251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = \"../data/train.csv\"\n",
    "prompt_type = 2\n",
    "test = load_split_data(data_path, prompt_type, MAX_LENGTH, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.019433,
     "end_time": "2024-06-29T18:08:33.078059",
     "exception": false,
     "start_time": "2024-06-29T18:08:33.058626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch = {k: [item[k] for item in batch] for k in (\"input_ids\", \"id\")}\n",
    "    batch_input = tokenizer(\n",
    "        batch[\"input_ids\"],\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LENGTH + 50\n",
    "    )\n",
    "    return batch_input, batch[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.021766,
     "end_time": "2024-06-29T18:08:33.111058",
     "exception": false,
     "start_time": "2024-06-29T18:08:33.089292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model, test_dataloader, gpu_id):\n",
    "    test_predictions = []\n",
    "    for batch in test_dataloader:\n",
    "        batch_input, idx = batch\n",
    "        for k in batch_input.keys():\n",
    "            batch_input[k] = batch_input[k].to(devices[gpu_id])\n",
    "        with torch.no_grad():\n",
    "            response = model.generate(**batch_input, max_new_tokens=1, return_dict_in_generate=True, output_scores=True)\n",
    "            score = response.scores[0]\n",
    "            A_prob, B_prob, C_prob = score[:, A_TOKEN_IDS], score[:, B_TOKEN_IDS], score[:, C_TOKEN_IDS]\n",
    "            logits = torch.Tensor([[A_prob, B_prob, C_prob]])\n",
    "            logits = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "            node_result = [[idx[i], logits[i]] for i in range(batch_size)]\n",
    "        test_predictions.append(node_result)\n",
    "    return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.307094,
     "end_time": "2024-06-29T18:08:33.429049",
     "exception": false,
     "start_time": "2024-06-29T18:08:33.121955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "libc = ctypes.CDLL(\"libc.so.6\")\n",
    "_ = gc.collect()\n",
    "libc.malloc_trim(0)\n",
    "\n",
    "device0 = torch.device(\"cuda:0\")\n",
    "device1 = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.018562,
     "end_time": "2024-06-29T18:08:33.459487",
     "exception": false,
     "start_time": "2024-06-29T18:08:33.440925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = \"google/gemma-2-9b-it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 100.875248,
     "end_time": "2024-06-29T18:10:14.410867",
     "exception": false,
     "start_time": "2024-06-29T18:08:33.535619",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "N_SAMPLES = test.shape[0]\n",
    "half = N_SAMPLES // 2\n",
    "sub_df_1 = test.iloc[0:half].copy().reset_index(drop=True)\n",
    "sub_df_2 = test.iloc[half:].copy().reset_index(drop=True)\n",
    "batch_size = 1\n",
    "\n",
    "for idx, model_path in enumerate(TRAINING_MODEL_PATH):\n",
    "    print(\"#\"*25)\n",
    "    print(\"=> Inferring\",model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "    config = AutoConfig.from_pretrained(base_model, trust_remote_code=True, token=\"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\")\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,  \n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True\n",
    "    )\n",
    "    base_model_0 = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        config=config,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=device0,\n",
    "        trust_remote_code=True,\n",
    "        token=\"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\"\n",
    "    )\n",
    "    new_model = model_path\n",
    "    model0 = PeftModel.from_pretrained(base_model_0, new_model).to(device0)\n",
    "    model0.eval()\n",
    "    \n",
    "    base_model_1 = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        config=config,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=device1,\n",
    "        trust_remote_code=True,\n",
    "        token=\"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\"\n",
    "    )\n",
    "    new_model = model_path\n",
    "    model1 = PeftModel.from_pretrained(base_model_1, new_model).to(device1)\n",
    "    model1.eval()\n",
    "    \n",
    "    models = [model0, model1]\n",
    "    devices = [device0, device1]\n",
    "    \n",
    "    A_TOKEN_IDS = tokenizer(\"A\",add_special_tokens=True, truncation=True, max_length=1024)[\"input_ids\"][1:]\n",
    "    B_TOKEN_IDS = tokenizer(\"B\",add_special_tokens=True, truncation=True, max_length=1024)[\"input_ids\"][1:]\n",
    "    C_TOKEN_IDS = tokenizer(\"C\",add_special_tokens=True, truncation=True, max_length=1024)[\"input_ids\"][1:]\n",
    "    \n",
    "\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    pred_0 = []\n",
    "    pred_1 = []\n",
    "    def inference_thread(gpu_id, lock, sub_test):\n",
    "        with lock:\n",
    "            print(f\"Thread {gpu_id} started on GPU {gpu_id}\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "        tokenized_dataset = InstructionDataSet(sub_test, tokenizer, MAX_LENGTH, 1)\n",
    "        test_dataloader = torch.utils.data.DataLoader(tokenized_dataset, batch_size=batch_size ,collate_fn=collate_fn)\n",
    "\n",
    "        sub_pred = inference(model=models[gpu_id], test_dataloader=test_dataloader, gpu_id=gpu_id)\n",
    "        assert len(sub_pred) == sub_test.shape[0]\n",
    "        with lock:\n",
    "            print(f\"Thread {gpu_id} finished on GPU {gpu_id}\")\n",
    "        if gpu_id == 0:\n",
    "            pred_0.append(sub_pred)\n",
    "        if gpu_id == 1:\n",
    "            pred_1.append(sub_pred)\n",
    "    \n",
    "    thread1 = threading.Thread(target=inference_thread, args=(0, lock, sub_df_1))\n",
    "    thread2 = threading.Thread(target=inference_thread, args=(1, lock, sub_df_2))\n",
    "\n",
    "    start_time = time.time()\n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "\n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "    print(f\"Inference Time {time.time() - start_time}\")\n",
    "    print(\"Both threads have finished.\")\n",
    "    \n",
    "    del model0, model1, models, tokenizer\n",
    "    torch.cuda.empty_cache()\n",
    "    _ = gc.collect()\n",
    "    libc.malloc_trim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.021118,
     "end_time": "2024-06-29T18:10:14.445038",
     "exception": false,
     "start_time": "2024-06-29T18:10:14.42392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pre(sub_pred):\n",
    "    processed_data = []\n",
    "    for item in sub_pred:\n",
    "        item = item[0]\n",
    "        id = item[0].item() \n",
    "        array_values = item[1].tolist()\n",
    "        processed_data.append([id] + array_values)\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.021228,
     "end_time": "2024-06-29T18:10:14.478955",
     "exception": false,
     "start_time": "2024-06-29T18:10:14.457727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = [j for i in pred_0 for j in i] + [j for i in pred_1 for j in i]\n",
    "prediction = get_pre(prediction)\n",
    "new_columns = [\"id\", \"winner_model_a\", \"winner_model_b\", \"winner_tie\"]\n",
    "new_columns_df = pd.DataFrame(prediction, columns=new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.025061,
     "end_time": "2024-06-29T18:10:14.516865",
     "exception": false,
     "start_time": "2024-06-29T18:10:14.491804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_columns_df = new_columns_df.groupby(\"id\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.023801,
     "end_time": "2024-06-29T18:10:14.553548",
     "exception": false,
     "start_time": "2024-06-29T18:10:14.529747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../data/train.csv\")\n",
    "assert new_columns_df.shape[0] == test.shape[0]\n",
    "test[new_columns] = new_columns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.024298,
     "end_time": "2024-06-29T18:10:14.592086",
     "exception": false,
     "start_time": "2024-06-29T18:10:14.567788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_columns = [\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]\n",
    "test[[\"id\"] + new_columns].to_csv(\"predictions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.030917,
     "end_time": "2024-06-29T18:10:14.668743",
     "exception": false,
     "start_time": "2024-06-29T18:10:14.637826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5308079,
     "sourceId": 8823073,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5152072,
     "sourceId": 8823248,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5333496,
     "sourceId": 8859134,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5342812,
     "sourceId": 8875834,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 28079,
     "sourceId": 33547,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 277.20851,
   "end_time": "2024-06-29T18:10:17.935414",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-29T18:05:40.726904",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a470c121d8a44ca8cb0b2fc3d4be187": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9c8e8045fb3849b8b0ccf2c634166c39",
       "placeholder": "​",
       "style": "IPY_MODEL_12abd0103fb4406e8ae272cdd141050b",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "12abd0103fb4406e8ae272cdd141050b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1944c525ab9f45f192dbc5d5e92ff1c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_31374fb3458940919e56a855c5485327",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a5030e57cdc14e5896586c9366deb86f",
       "value": 4
      }
     },
     "1f7dbb5c437243aa9e11005f77caa2a0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "25c66d4d84fb4528ae840cdaecdff086": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2963e63dc59a478798b51e8d8209fc57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "29a53e0b47da4a45a659c1cc3bc7cdff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2cf94bfc64774b97a51e9ffcc87c0e47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "31374fb3458940919e56a855c5485327": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c8e8045fb3849b8b0ccf2c634166c39": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d03e8bb8e314e7abd4bf1182c4f4e12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f616c58f465d4d2d860bc865b0808c85",
       "placeholder": "​",
       "style": "IPY_MODEL_25c66d4d84fb4528ae840cdaecdff086",
       "value": " 4/4 [01:15&lt;00:00, 16.24s/it]"
      }
     },
     "a5030e57cdc14e5896586c9366deb86f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ad5b12ce37f94c64b1c475f7c72fdcfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "be25bf0a6e3d4de8ac26824702c369f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0a470c121d8a44ca8cb0b2fc3d4be187",
        "IPY_MODEL_1944c525ab9f45f192dbc5d5e92ff1c1",
        "IPY_MODEL_9d03e8bb8e314e7abd4bf1182c4f4e12"
       ],
       "layout": "IPY_MODEL_2963e63dc59a478798b51e8d8209fc57"
      }
     },
     "c04cc03313844ff5be116fc2e3f39c24": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c7f5e4d0a3cd4ddf92f02d508abd9d93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cf68ab9ca3d4407792665d5ec138ea56",
        "IPY_MODEL_f6b3970962ae4b53954e3b4c743a8228",
        "IPY_MODEL_cfcf7efa3a024254aaca68993bdd581c"
       ],
       "layout": "IPY_MODEL_c04cc03313844ff5be116fc2e3f39c24"
      }
     },
     "cf68ab9ca3d4407792665d5ec138ea56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_de846cbe313948a7b431cc38c37674c4",
       "placeholder": "​",
       "style": "IPY_MODEL_2cf94bfc64774b97a51e9ffcc87c0e47",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "cfcf7efa3a024254aaca68993bdd581c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d451fbb89fcd4b889cc82dfba4c84c2d",
       "placeholder": "​",
       "style": "IPY_MODEL_29a53e0b47da4a45a659c1cc3bc7cdff",
       "value": " 4/4 [00:16&lt;00:00,  3.68s/it]"
      }
     },
     "d451fbb89fcd4b889cc82dfba4c84c2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de846cbe313948a7b431cc38c37674c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f616c58f465d4d2d860bc865b0808c85": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f6b3970962ae4b53954e3b4c743a8228": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1f7dbb5c437243aa9e11005f77caa2a0",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ad5b12ce37f94c64b1c475f7c72fdcfc",
       "value": 4
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
